{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SNR_Zadanie2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/czelijm/SNR_18Z/blob/master/SNR_Zadanie2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "xNYTFDX7h7W0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Podpinanie dysku google, importowanie bibliotek oraz definicje funkcji\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "BoWzg1mRwR4D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sOJl-vA-w-Oy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HM4VOuaHKuv6",
        "colab_type": "code",
        "outputId": "cbeaec96-9250-4ac7-9379-0c51a2c88baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd /content/drive/WorkingSpaceColab/SNR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/WorkingSpaceColab/SNR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q9cacGOxzsZe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " ls -la"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r4fxeSL9ymH4",
        "colab_type": "code",
        "outputId": "85268121-1b57-43e4-b6ad-6a1efef4356a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from skimage import feature\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "# from keras.preprocessing.image import load_img\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation, InputLayer\n",
        "from matplotlib import pyplot\n",
        "from skimage.util import random_noise\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4jF5To_s9euB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LR_ADAMA = 0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-fYypFspx5UE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def check_numpy_set_exist(name):\n",
        "    if os.path.isfile(\"dataX-\" + name + \".npy\") and os.path.isfile(\"dataY-\" + name + \".npy\"):\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VqWxskSMyWQJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_numpy_set(name):\n",
        "    x = np.load(\"dataX-\" + name + \".npy\")\n",
        "    y = np.load(\"dataY-\" + name + \".npy\")\n",
        "    return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bDSZBbEwy4eJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_id_class_dictionary(y_val):\n",
        "    # make dictionary of classes\n",
        "    y_val.sort()\n",
        "    y_val = Counter(y_val).keys()\n",
        "\n",
        "    class_id = {}\n",
        "    temp_list_id = []\n",
        "    count = 1\n",
        "\n",
        "    for i in y_val:\n",
        "        temp_list_id.append((i, count))\n",
        "        count += 1\n",
        "\n",
        "    for word, _id in temp_list_id:\n",
        "        class_id[word] = _id\n",
        "    print(class_id)\n",
        "\n",
        "    return class_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ffW8wHF4zHDh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cvt2_id_class_list(dictionary_class_id, word_list):\n",
        "    # covert word list of class to id list of class\n",
        "    y_teach = []\n",
        "    for i in word_list:\n",
        "        y_teach.append(dictionary_class_id[i])\n",
        "    return y_teach"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k4TAPTAgzbC-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cv2_id_class_as_vector(y_val_temp, num_of_class):\n",
        "    y_val = []\n",
        "    for i in y_val_temp:\n",
        "        y = [0] * num_of_class\n",
        "        y[i - 1] = 1\n",
        "        y_val.append(y)\n",
        "    np.asarray(y_val)\n",
        "    return y_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nPS0RMs02d0b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Dane trengowe wczytywanie rozpoczęte\")\n",
        "x_teach, y_teach = load_numpy_set(\"teach\")\n",
        "print(\"Dane trengowe wczytane\")\n",
        "  \n",
        "print(\"Dane testowe wczytywanie rozpoczęte\")\n",
        "x_test, y_test_temp = load_numpy_set(\"test\")\n",
        "print(\"Dane testowe wczytane\")\n",
        "y_test_temp_copy = y_test_temp.copy()\n",
        "\n",
        "# random Split Data set to teach\n",
        "x_teach, x_val, y_teach_temp1, y_val_temp1 = train_test_split(x_teach, y_teach, test_size=0.3, random_state=42)\n",
        "print(\"Dane podzielone na zbiór treningowy i walidacyjny\")\n",
        "\n",
        "# number of class in set\n",
        "num_of_class = len(set(y_test_temp_copy))\n",
        "\n",
        "# make idClasses\n",
        "id_class_dictionary = make_id_class_dictionary(y_test_temp_copy)\n",
        "\n",
        "# convert from wordList to numberList Of class\n",
        "y_teach_temp2 = cvt2_id_class_list(id_class_dictionary, y_teach_temp1)\n",
        "y_val_temp2 = cvt2_id_class_list(id_class_dictionary, y_val_temp1)\n",
        "\n",
        "# get final representation of labels as vector ex. [0 0 0 0 ..... 0 1 0 0 0] - outputs of network\n",
        "y_val = cv2_id_class_as_vector(y_val_temp2, num_of_class)\n",
        "y_teach = cv2_id_class_as_vector(y_teach_temp2, num_of_class)\n",
        "\n",
        "\n",
        "#zbiór testowy\n",
        "y_test_tmp = cvt2_id_class_list(id_class_dictionary, y_test_temp)\n",
        "y_test = cv2_id_class_as_vector(y_test_tmp, num_of_class)\n",
        "#zmiana nazw zbioru testowego\n",
        "x_test_temp=x_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bbM4hCGH9wwr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2a  zaimplementować dowolnie wybraną przez siebie głęboką sieć splotową - bez uczenia"
      ]
    },
    {
      "metadata": {
        "id": "klf3ESX9pcwW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## wagi zaincjalizowane z \"imagenet\":"
      ]
    },
    {
      "metadata": {
        "id": "aIS0WaHi67d_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filepath_not_trained=\"VGG_not_trained.hdf5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BH7vtpWx3RF-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg_conv_not_trained = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
        "model_not_trained = Sequential()\n",
        "model_not_trained.add(vgg_conv_not_trained)\n",
        "# # Dodawanie warstw\n",
        "model_not_trained.add(layers.Flatten())\n",
        "model_not_trained.add(layers.Dense(71, activation='softmax'))\n",
        "# Schemat modelu\n",
        "model_not_trained.summary()\n",
        "\n",
        "model_not_trained.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=0.0001),\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "\n",
        "print(model_not_trained.metrics_names)\n",
        "print(model_not_trained.evaluate(x_val, np.asarray(y_val)))\n",
        "print(model_not_trained.evaluate(x_test_temp, np.asarray(y_test)))\n",
        "# results_not_trained = model_not_trained.fit(x_teach, np.asarray(y_teach), epochs=NUM_OF_EPOCH_not_trained, batch_size=BATH_SIZE_not_trained, validation_data=(x_val, np.asarray(y_val)),\n",
        "#                     verbose=1,callbacks= cb_not_trained)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D0qcd0F84Zt0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_not_trained.save(filepath_not_trained)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i2wolBocCumt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##z losowo zaincjanizowanymi wagami:"
      ]
    },
    {
      "metadata": {
        "id": "4nqZW1wcCsjD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg_conv_not_trained_rand = VGG16(weights=None, include_top=False, input_shape=(100, 100, 3))\n",
        "model_not_trained_rand = Sequential()\n",
        "model_not_trained_rand.add(vgg_conv_not_trained_rand)\n",
        "# # Dodawanie warstw\n",
        "model_not_trained_rand.add(layers.Flatten())\n",
        "model_not_trained_rand.add(layers.Dense(71, activation='softmax'))\n",
        "# Schemat modelu\n",
        "model_not_trained_rand.summary()\n",
        "\n",
        "model_not_trained_rand.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=0.0001),\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "\n",
        "print(model_not_trained_rand.metrics_names)\n",
        "print(model_not_trained_rand.evaluate(x_val, np.asarray(y_val)))\n",
        "print(model_not_trained_rand.evaluate(x_test_temp, np.asarray(y_test)))\n",
        "# results_not_trained = model_not_trained.fit(x_teach, np.asarray(y_teach), epochs=NUM_OF_EPOCH_not_trained, batch_size=BATH_SIZE_not_trained, validation_data=(x_val, np.asarray(y_val)),\n",
        "#                     verbose=1,callbacks= cb_not_trained)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j5nhrqmd5H0W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filepath_not_trained_rand=\"VGG_not_trained_rand.hdf5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cXWv962i5ID3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_not_trained_rand.save(filepath_not_trained_rand)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-_toSi-QAPag",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2b  zaimplementować dowolnie wybraną przez siebie głęboką sieć splotową - z uczeniem"
      ]
    },
    {
      "metadata": {
        "id": "ZsiVwHdRAwCM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_OF_EPOCH = 1\n",
        "BATH_SIZE = 100\n",
        "filepath=\"VGG_trained.hdf5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KBUbjwrJ2fWy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
        "vgg_conv = VGG16(weights=None, include_top=False, input_shape=(100, 100, 3))\n",
        "\n",
        "\n",
        "# Tworzenie nowego modelu\n",
        "model = Sequential()\n",
        "model.add(vgg_conv)\n",
        "\n",
        "# Dodawanie warstw\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(71, activation='softmax'))\n",
        "\n",
        "\n",
        "# Schemat modelu\n",
        "model.summary()\n",
        "\n",
        "# Konfiguracja sieci i danych\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=0.0001),\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, verbose=0, save_best_only=True)\n",
        "cb = [checkpoint] \n",
        "\n",
        "results = model.fit(x_teach, np.asarray(y_teach), epochs=2, batch_size=BATH_SIZE, validation_data=(x_test, np.asarray(y_test)),\n",
        "                    verbose=1,callbacks= cb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RlQWTOvzOA7I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_vgg_model = load_model(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4OwGXZ7mN5uL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print ('Start evaluating')\n",
        "evaluation_result = best_vgg_model.evaluate(x_test_temp, np.asarray(y_test))\n",
        "print ('Finish evaluating:')\n",
        "print(best_vgg_model.metrics_names)\n",
        "print(evaluation_result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g3qjWgQmFosm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2c wykonać zwielokrotnianie danych"
      ]
    },
    {
      "metadata": {
        "id": "SOUte6l6AALO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  Obroty"
      ]
    },
    {
      "metadata": {
        "id": "BR-AAn8Ijssx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# obroty\n",
        "datagennewnew_rot = ImageDataGenerator(rotation_range=90,\n",
        "                                  fill_mode='nearest')\n",
        "datagennewnew_rot.fit(x_teach)\n",
        "for X_batch, y_batch in datagennewnew_rot.flow(x_teach, y_teach, batch_size=9):\n",
        "    for i in range(0, 9):\n",
        "        bgr = X_batch[i].reshape(100, 100, 3).astype('uint8')\n",
        "        rgb = bgr[...,::-1]\n",
        "        pyplot.imshow(rgb)\n",
        "    pyplot.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zz68DqRbTU92",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
        "# Tworzenie nowego modelu\n",
        "model = Sequential()\n",
        "model.add(vgg_conv)\n",
        "\n",
        "# Dodawanie warstw\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(71, activation='softmax'))\n",
        "\n",
        "# Schemat modelu\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "30EGeNrNQYUJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#datagennewnew_rot = ImageDataGenerator(rotation_range=90,\n",
        "#                                      fill_mode='nearest')\n",
        "#datagennewnew_rot.fit(x_teach)\n",
        "traind_data_generator = datagennewnew_rot.flow(x_teach, np.array(y_teach), batch_size=100)\n",
        "\n",
        "# Konfiguracja sieci i danych\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=0.0001),\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "\n",
        "results = model.fit_generator(traind_data_generator, steps_per_epoch=len(x_teach) / 100, epochs=2,validation_data=(x_test, np.asarray(y_test)), verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bszBEL55Jlls",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_path_2_save_file=\"VGG_based_model_rotated_images.hdf5\"\n",
        "model.save(file_path_2_save_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qF0azn5KOr2L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"rotated_loss\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Test Loss'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JKLuxwNuOsga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"rotated_accuracy\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['categorical_accuracy'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_categorical_accuracy'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Test Accuracy'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Categorical Accuracy',fontsize=16)\n",
        "plt.title('Categorical Accuracy Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8MVvf-iQAIJL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Przesunięcie"
      ]
    },
    {
      "metadata": {
        "id": "S-goWanklW51",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#przesunięcia\n",
        "datagennewnew_shift = ImageDataGenerator(width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  fill_mode='nearest')\n",
        "datagennewnew_shift.fit(x_teach)\n",
        "for X_batch, y_batch in datagennewnew_shift.flow(x_teach, y_teach, batch_size=9):\n",
        "    for i in range(0, 9):\n",
        "        bgr = X_batch[i].reshape(100, 100, 3).astype('uint8')\n",
        "        rgb = bgr[...,::-1]\n",
        "        pyplot.imshow(rgb)\n",
        "    pyplot.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pos9XxRbTy2X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
        "# Tworzenie nowego modelu\n",
        "model = Sequential()\n",
        "model.add(vgg_conv)\n",
        "\n",
        "# Dodawanie warstw\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(71, activation='softmax'))\n",
        "\n",
        "# Schemat modelu\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p38XLzo2Qa8Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "traind_data_generator = datagennewnew_shift.flow(x_teach, np.array(y_teach), batch_size=100)\n",
        "\n",
        "# Konfiguracja sieci i danych\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=0.0001),#0.0001\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "results = model.fit_generator(traind_data_generator, steps_per_epoch=len(x_teach) / 100, epochs=2,validation_data=(x_test, np.asarray(y_test)), verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4fGvEEbIPbqn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_path_2_save_file=\"VGG_based_model_shifted_images.hdf5\"\n",
        "model.save(file_path_2_save_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ovbKq8lXQURx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"shifted_loss\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Test Loss'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NTBIRt9wQVGN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"shifted_accuracy\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['categorical_accuracy'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_categorical_accuracy'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Test Accuracy'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Categorical Accuracy',fontsize=16)\n",
        "plt.title('Categorical Accuracy Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xonxwfS6-mB5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## noise gaussian"
      ]
    },
    {
      "metadata": {
        "id": "XbIWVvuoYZ1J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#noise gaussian\n",
        "datagennewnew_noise = ImageDataGenerator(fill_mode='nearest')\n",
        "x_teach_noise = np.copy(x_teach)\n",
        "\n",
        "for x in range(0, x_teach_noise.shape[0]):\n",
        "    imgtmp = (x_teach_noise[x]).astype(np.float32) / 255.0\n",
        "    imgtmp = random_noise(imgtmp,mode='gaussian',var=0.05**2)\n",
        "    imgtmp=imgtmp * 255.0\n",
        "    imgtmp= imgtmp.astype(np.int)\n",
        "    x_teach_noise[x] = imgtmp\n",
        "\n",
        "datagennewnew_noise.fit(x_teach_noise)\n",
        "for X_batch, y_batch in datagennewnew_noise.flow(x_teach_noise, y_teach, batch_size=9):\n",
        "    for i in range(0, 9):\n",
        "        bgr = X_batch[i].reshape(100, 100, 3).astype('uint8')\n",
        "        rgb = bgr[...,::-1]\n",
        "        pyplot.imshow(rgb)\n",
        "    pyplot.show()\n",
        "    break  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W9hRxOkx-aH6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
        "# Tworzenie nowego modelu\n",
        "model = Sequential()\n",
        "model.add(vgg_conv)\n",
        "\n",
        "# Dodawanie warstw\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(71, activation='softmax'))\n",
        "\n",
        "# Schemat modelu\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sQm5TfJJQDOG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "traind_data_generator = datagennewnew_noise.flow(x_teach, np.array(y_teach), batch_size=100)\n",
        "\n",
        "# Konfiguracja sieci i danych\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=LR_ADAMA),\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "results = model.fit_generator(traind_data_generator, steps_per_epoch=len(x_teach) / 100, epochs=2,validation_data=(x_test, np.asarray(y_test)), verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4grUVzkly0dV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_file_gaussian_noise=\"best_VGG_based_model_gauss.hdf5\"#przeuczona\n",
        "model.save(path_file_gaussian_noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W9ypI75fQmlb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"gaussian_noise_loss\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Test Loss'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7cu0f6t-QqhW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"gaussian_noise_accuracy\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['categorical_accuracy'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_categorical_accuracy'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Test Accuracy'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Categorical Accuracy',fontsize=16)\n",
        "plt.title('Categorical Accuracy Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vqP4kUViAXSR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## noise s&p"
      ]
    },
    {
      "metadata": {
        "id": "T1bRw5ez9VU_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#noise s&p\n",
        "datagennewnew_noise = ImageDataGenerator(fill_mode='nearest')\n",
        "x_teach_noise = np.copy(x_teach)\n",
        "\n",
        "for x in range(0, x_teach_noise.shape[0]):\n",
        "    imgtmp = (x_teach_noise[x]).astype(np.float32) / 255.0\n",
        "    imgtmp = random_noise(imgtmp,mode='s&p')\n",
        "    imgtmp=imgtmp * 255.0\n",
        "    imgtmp= imgtmp.astype(np.int)\n",
        "    x_teach_noise[x] = imgtmp\n",
        "\n",
        "datagennewnew_noise.fit(x_teach_noise)\n",
        "for X_batch, y_batch in datagennewnew_noise.flow(x_teach_noise, y_teach, batch_size=9):\n",
        "    for i in range(0, 9):\n",
        "        bgr = X_batch[i].reshape(100, 100, 3).astype('uint8')\n",
        "        rgb = bgr[...,::-1]\n",
        "        pyplot.imshow(rgb)\n",
        "    pyplot.show()\n",
        "    break  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WoLBrMH-BQxm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
        "# Tworzenie nowego modelu\n",
        "model = Sequential()\n",
        "model.add(vgg_conv)\n",
        "\n",
        "# Dodawanie warstw\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(71, activation='softmax'))\n",
        "\n",
        "# Schemat modelu\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IIPkUTdQB2r4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "traind_data_generator = datagennewnew_noise.flow(x_teach, np.array(y_teach), batch_size=100)\n",
        "\n",
        "# Konfiguracja sieci i danych\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=LR_ADAMA),#125\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "results = model.fit_generator(traind_data_generator, steps_per_epoch=len(x_teach) / 100, epochs=2,validation_data=(x_test, np.asarray(y_test)), verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GCQysYJi2nvy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_file_sp_noise=\"VGG_based_model_sp.hdf5\"#przeuczona\n",
        "model.save(path_file_sp_noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hBHjALl8CC0B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"sp_noise_loss\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Test Loss'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y5Q3E0zRCF17",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"sp_noise_accuracy\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['categorical_accuracy'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_categorical_accuracy'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Test Accuracy'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Categorical Accuracy',fontsize=16)\n",
        "plt.title('Categorical Accuracy Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tDSGbqDNAdiQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## noise speckle"
      ]
    },
    {
      "metadata": {
        "id": "J_t70kw-CWla",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#noise s&p\n",
        "datagennewnew_noise = ImageDataGenerator(fill_mode='nearest')\n",
        "x_teach_noise = np.copy(x_teach)\n",
        "\n",
        "for x in range(0, x_teach_noise.shape[0]):\n",
        "    imgtmp = (x_teach_noise[x]).astype(np.float32) / 255.0\n",
        "    imgtmp = random_noise(imgtmp,mode='speckle')\n",
        "    imgtmp=imgtmp * 255.0\n",
        "    imgtmp= imgtmp.astype(np.int)\n",
        "    x_teach_noise[x] = imgtmp\n",
        "\n",
        "datagennewnew_noise.fit(x_teach_noise)\n",
        "for X_batch, y_batch in datagennewnew_noise.flow(x_teach_noise, y_teach, batch_size=9):\n",
        "    for i in range(0, 9):\n",
        "        bgr = X_batch[i].reshape(100, 100, 3).astype('uint8')\n",
        "        rgb = bgr[...,::-1]\n",
        "        pyplot.imshow(rgb)\n",
        "    pyplot.show()\n",
        "    break  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kIhidDS-Ca-2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
        "# Tworzenie nowego modelu\n",
        "model = Sequential()\n",
        "model.add(vgg_conv)\n",
        "\n",
        "# Dodawanie warstw\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(71, activation='softmax'))\n",
        "\n",
        "# Schemat modelu\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7AisFuq4CeHc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "traind_data_generator = datagennewnew_noise.flow(x_teach, np.array(y_teach), batch_size=100)\n",
        "\n",
        "# Konfiguracja sieci i danych\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=0.0001),\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "results = model.fit_generator(traind_data_generator, steps_per_epoch=len(x_teach) / 100, epochs=2,validation_data=(x_test, np.asarray(y_test)), verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_akzwWO-tYE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_file_speckle_noise=\"VGG_based_model_speckle.hdf5\"#przeuczona\n",
        "model.save(path_file_speckle_noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NzDXVffnCgbG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"speckle_loss\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Test Loss'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tFEByHMjCkkT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"speckle_accuracy\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['categorical_accuracy'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_categorical_accuracy'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Test Accuracy'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Categorical Accuracy',fontsize=16)\n",
        "plt.title('Categorical Accuracy Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mCkAXsqD7_kM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#2d  różne metody   regularyzacji: ​ dropout ,wczesne zatrzymanie uczenia, wpływ przesłonięcia  obrazów \n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "cSBAOs74hJlU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Rozmiary deskryptora"
      ]
    },
    {
      "metadata": {
        "id": "dOIBW-aBKtxX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tworzenie struktury sieci\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.InputLayer((100, 100, 3)))\n",
        "model.add(layers.Convolution2D(64, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block1_conv1'))\n",
        "model.add( layers.Convolution2D(64, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block1_conv2'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
        "\n",
        "# Block 2\n",
        "model.add( layers.Convolution2D(128, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block2_conv1'))\n",
        "model.add( layers.Convolution2D(128, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block2_conv2'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
        "\n",
        "# Block 3\n",
        "model.add( layers.Convolution2D(256, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block3_conv1'))\n",
        "model.add( layers.Convolution2D(256, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block3_conv2'))\n",
        "model.add( layers.Convolution2D(256, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block3_conv3'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
        "\n",
        "# Block 4\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block4_conv1'))\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block4_conv2'))\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block4_conv3'))\n",
        "model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
        "\n",
        "# Block 5\n",
        "model.add(layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block5_conv1'))\n",
        "model.add(layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block5_conv2'))\n",
        "\n",
        "\n",
        "# na tej warstwie trzeba dokonać modyfikować\n",
        "model.add( layers.Convolution2D(256, (6, 6),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block5_conv3'))\n",
        "\n",
        "# trzy różne rozmairy deskryptora zmieniamy w tej warstwie powyżej \"block5_conv3\"\n",
        "# model.add(layers.Convolution2D(64, (3, 3),\n",
        "#                          activation='relu',\n",
        "#                          padding='same',\n",
        "#                          name='block5_conv3'))\n",
        "# model.add(layers.Convolution2D(512, (5, 5),\n",
        "#                          activation='relu',\n",
        "#                          padding='same',\n",
        "#                          name='block5_conv3'))\n",
        "# model.add(layers.Convolution2D(512, (3, 3),\n",
        "#                          activation='relu',\n",
        "#                          padding='same',\n",
        "#                          name='block5_conv3'))\n",
        "###########################################\n",
        "\n",
        "\n",
        "\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(71, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6NhC1-4LLEDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Konfiguracja sieci i danych\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=0.0001),\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "results = model.fit(x_teach, np.asarray(y_teach), epochs=2, batch_size=100, validation_data=(x_test, np.asarray(y_test)),\n",
        "                    verbose=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JtvS6eO0Fusg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_file_Desc=\"VGG_based_descr_256_3_3.hdf5\"#przeuczona\n",
        "model.save(path_file_Desc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nu8IaYhIOv4s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"descriptor_size_256_3_3_loss\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Test Loss'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p5NupSp4Oyn1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"descriptor_size_256_3_3_accuracy\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['categorical_accuracy'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_categorical_accuracy'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Test Accuracy'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Categorical Accuracy',fontsize=16)\n",
        "plt.title('Categorical Accuracy Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iTxcj2zzhjeZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dropout"
      ]
    },
    {
      "metadata": {
        "id": "76JGHLtW5qgz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(layers.InputLayer((100, 100, 3)))\n",
        "model.add(layers.Convolution2D(64, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block1_conv1'))\n",
        "model.add( layers.Convolution2D(64, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block1_conv2'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
        "\n",
        "# Block 2\n",
        "model.add( layers.Convolution2D(128, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block2_conv1'))\n",
        "model.add( layers.Convolution2D(128, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block2_conv2'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
        "\n",
        "# Block 3\n",
        "model.add( layers.Convolution2D(256, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block3_conv1'))\n",
        "model.add( layers.Convolution2D(256, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block3_conv2'))\n",
        "model.add( layers.Convolution2D(256, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block3_conv3'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
        "\n",
        "# Block 4\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block4_conv1'))\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block4_conv2'))\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block4_conv3'))\n",
        "model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
        "\n",
        "# Block 5\n",
        "model.add(layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block5_conv1'))\n",
        "model.add(layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block5_conv2'))\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block5_conv3'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "#tutaj zminaić drouput, można by też robić po każdej grupie warstw conv \n",
        "model.add(Dropout(0.1)) # mniejsze od 0.1\n",
        "model.add(layers.Dense(71, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3zVhy6Io5cS7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Konfiguracja sieci i danych\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=0.0001),\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "results = model.fit(x_teach, np.asarray(y_teach), epochs=2, batch_size=100, validation_data=(x_test, np.asarray(y_test)),\n",
        "                    verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hG5YR6Nz7Qnq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"robocza_nazwa_loss\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Test Loss'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3MPmXY-VAFb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"robocza_nazwa_accuracy\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['categorical_accuracy'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_categorical_accuracy'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Test Accuracy'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Categorical Accuracy',fontsize=16)\n",
        "plt.title('Categorical Accuracy Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kK4Rs5oniL_v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Wczesne zatrzymanie uczenia"
      ]
    },
    {
      "metadata": {
        "id": "VAT_jaCPW8-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(layers.InputLayer((100, 100, 3)))\n",
        "model.add(layers.Convolution2D(64, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block1_conv1'))\n",
        "model.add( layers.Convolution2D(64, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block1_conv2'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
        "\n",
        "# Block 2\n",
        "model.add( layers.Convolution2D(128, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block2_conv1'))\n",
        "model.add( layers.Convolution2D(128, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block2_conv2'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
        "\n",
        "# Block 3\n",
        "model.add( layers.Convolution2D(256, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block3_conv1'))\n",
        "model.add( layers.Convolution2D(256, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block3_conv2'))\n",
        "model.add( layers.Convolution2D(256, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block3_conv3'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
        "\n",
        "# Block 4\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block4_conv1'))\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block4_conv2'))\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block4_conv3'))\n",
        "model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
        "\n",
        "# Block 5\n",
        "model.add(layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block5_conv1'))\n",
        "model.add(layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block5_conv2'))\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block5_conv3'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(71, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lVq7XvaeW-zq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Konfiguracja sieci i danych\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=0.0001),\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "cb_early = [EarlyStopping(monitor='val_loss', patience=2, min_delta=0.1)]\n",
        "\n",
        "results = model.fit(x_teach, np.asarray(y_teach), epochs=2, batch_size=100, validation_data=(x_test, np.asarray(y_test)),\n",
        "                   verbose=1,callbacks= cb_early)\n",
        "#model.fit(x_teach,np.asarray(y_teach),batch_size=100,epochs=3,validation_data=(x_test, np.asarray(y_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tTMAl2YYHnzJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"robocza_nazwa_loss\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Test Loss'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ksDp33ZuHoqi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"robocza_nazwa_accuracy\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['categorical_accuracy'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_categorical_accuracy'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Test Accuracy'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Categorical Accuracy',fontsize=16)\n",
        "plt.title('Categorical Accuracy Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "004qedzNiWO_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Wpływ przesłonięcia obrazów"
      ]
    },
    {
      "metadata": {
        "id": "ylbpv6WvQDtu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.InputLayer((100, 100, 3)))\n",
        "model.add(layers.Convolution2D(64, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block1_conv1'))\n",
        "model.add( layers.Convolution2D(64, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block1_conv2'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
        "\n",
        "# Block 2\n",
        "model.add( layers.Convolution2D(128, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block2_conv1'))\n",
        "model.add( layers.Convolution2D(128, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block2_conv2'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
        "\n",
        "# Block 3\n",
        "model.add( layers.Convolution2D(256, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block3_conv1'))\n",
        "model.add( layers.Convolution2D(256, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block3_conv2'))\n",
        "model.add( layers.Convolution2D(256, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block3_conv3'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
        "\n",
        "# Block 4\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block4_conv1'))\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block4_conv2'))\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block4_conv3'))\n",
        "model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
        "\n",
        "# Block 5\n",
        "model.add(layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block5_conv1'))\n",
        "model.add(layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block5_conv2'))\n",
        "model.add( layers.Convolution2D(512, (3, 3),\n",
        "                         activation='relu',\n",
        "                         padding='same',\n",
        "                         name='block5_conv3'))\n",
        "model.add( layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(71, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Y-jG0LdQNPC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tu jest parametr do zmiany liczby procentów zaciemnienia obrazu - teraz jest 40 procent\n",
        "percent = 40\n",
        "datagennewnew_cover = ImageDataGenerator(fill_mode='nearest')\n",
        "x_teach_noise = np.copy(x_teach)\n",
        "\n",
        "for x in range(0, x_teach_noise.shape[0]):\n",
        "    img = np.reshape(x_teach_noise[x], (100, 100, 3))\n",
        "    for h in range(img.shape[0]):\n",
        "        for j in range(img.shape[1]):\n",
        "            if h < percent:\n",
        "                img[j, h] = 0\n",
        "\n",
        "datagennewnew_cover.fit(x_teach_noise)\n",
        "for X_batch, y_batch in datagennewnew_cover.flow(x_teach_noise, y_teach, batch_size=9):\n",
        "    for i in range(0, 9):\n",
        "        pyplot.subplot(330 + 1 + i)\n",
        "        pyplot.imshow(X_batch[i].reshape(100, 100, 3).astype('uint8'))\n",
        "    pyplot.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H8UeVt4oQbq8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Konfiguracja sieci i danych\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=0.0001),\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "\n",
        "results = model.fit_generator(traind_data_generator, steps_per_epoch=len(x_teach_noise) / 100, epochs=1,validation_data=(x_test, np.asarray(y_test)), verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7_m93ABvUeKE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_file_occulusion=\"VGG_based_occulusion_60.hdf5\"#przeuczona\n",
        "model.save(path_file_occulusion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AELg84ERQksU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"occulusion_60_loss\"\n",
        "# plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Test Loss'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vqt3gQksQ-UO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveToFile = \"occulusion_60_accuracy\"\n",
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(results.history['categorical_accuracy'],'r',linewidth=3.0)\n",
        "plt.plot(results.history['val_categorical_accuracy'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Test Accuracy'],fontsize=18)\n",
        "plt.xlabel('Number of epochs ',fontsize=16)\n",
        "plt.ylabel('Categorical Accuracy',fontsize=16)\n",
        "plt.title('Categorical Accuracy Plot',fontsize=16)\n",
        "plt.savefig(\"wykresy/\" + saveToFile)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}